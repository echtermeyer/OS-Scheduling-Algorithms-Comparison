% !TEX root =  master.tex
\chapter{OS Scheduling Algorithmen}
Das Kernstück eines jeden modernen Betriebssystems is dessen Fähigkeit eine Vielzahl von Prozessen effizient und effektiv zu verwalten. Diese Prozessverwaltung, auch bekannt als Scheduling, ist eine komplexe Aufgabe, welche darüber entscheidet, welcher Prozess zu welchem Zeitpunkt von der \ac{CPU} verarbeitet wird. Da moderne Betriebssysteme stets eine hohe Anzahl von Hintergrundprozessen bis hin zu anspruchsvollen Anwendungen verarbeiten müssen, ist die Verwendung leistungsfähiger OS Scheduling Algorithmen essentiell. Im folgenden werden drei unterschiedliche Algorithmen des OS Scheduling vorgestellt, mit aufsteigender Komplexität. Jeder dieser Algorithmen hat eigenen Stärken und Schwächen, die ihn für bestimmte Szenarien und Anforderungen geeignet machen. Von den einfachen, aber grundlegenden Ansätzen wie First Come First Serve bis hin zu komplexeren Strategien wie Multilevel Queue Scheduling, spiegelt die Entwicklung dieser Algorithmen die Fortschritte in der Computertechnologie und unser zunehmendes Verständnis von effizientem Prozessmanagement wider.

\section{First-Come-First-Serve}

Einer der grundlegenden Scheduling Algorithmen für Betriebssysteme ist \ac{FCFS}, welcher auch als \ac{FIFO} bekannt ist. \ac{FCFS} verarbeitet eingehende Prozesse in der Reihenfolge ihres Eintreffens, wobei der zuerst ankommende Prozess als erstes prozessiert wird. Implementiert wird \ac{FCFS} für gewöhnlich als Warteschlange, aus welcher eingehende Prozesse anschließend sequentiell verarbeitet werden können. 

\begin{algorithm}
	\caption{\ac{FCFS} Scheduling Algorithm}
	\label{alg:fcfs}
	\begin{algorithmic}[1]
		\Procedure{FCFS}{$processes$}
		\State $n \gets \text{length}(processes)$
		\State Sort $processes$ by arrival time
		\For{$i \gets 1$ to $n$}
		\If{$i = 1$}
		\State $start\_time[i] \gets processes[i].arrival$
		\Else
		\State $start\_time[i] \gets \max(processes[i].arrival, finish\_time[i-1])$
		\EndIf
		\State $finish\_time[i] \gets start\_time[i] + processes[i].burst$
		\State $waiting\_time[i] \gets start\_time[i] - processes[i].arrival$
		\State $turnaround\_time[i] \gets finish\_time[i] - processes[i].arrival$
		\EndFor
		\State \textbf{return} $start\_time$, $finish\_time$, $waiting\_time$, $turnaround\_time$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Der Pseudocode in Abbildung \ref{alg:fcfs} implementiert den \ac{FCFS}-Scheduling-Algorithmus für einen Satz von Prozessen. Dabei wird angenommen, dass jeder Prozess Eigenschaften wie Ankunftszeit (arrival) und Ausführungszeit (burst) hat. Der Algorithmus berechnet die Startzeit, Endzeit, Wartezeit und Umlaufzeit für jeden Prozess. 

Der große Vorteil von \ac{FCFS} liegt in dessen Einfachheit und der hieraus resultierenden leichten Implementierbarkeit. Daher wird dieser auch oft in Lehrbüchern im Kontext grundlegender Betriebssystemkonzepte diskutiert. % Silberschatz, Galvin und Gagne (2018)
Zudem ist \ac{FCFS} transparent und einfach vorhersehbar, da die Reihenfolge und Bearbeitungsdauer aller Prozesse lediglich von deren Ankunftszeiten abhängig ist. Ein zusätzlicher Vorteil liegt in der fairen Behandlung aller Prozesse, welche ohne Bevorzugung stattfindet, da jeder Prozess in der Reihenfolge seines Eintreffens bearbeitet wird. % (Stallings, 2012)

Nichtsdestotrotz, weist \ac{FCFS} auch signifikante Nachteile auf, weshalb in der Praxis meist von einer alleinigen Nutzung dieses Algorithmus abgesehen wird. Das wesentliche Problem ist nämlich der Convoy-Effekt, bei dem ein langer Prozess, der früh in der Warteschlange erscheint, nachfolgende, kürzere Prozesse verzögert. Diese Situation führt zu einer ineffizienten \ac{CPU}-Auslastung und verlängerten Wartezeiten. % Tanenbaum, Bos (2014) 
Weiterhin berücksichtigt \ac{FCFS} neben der Dauer auch nicht die unterschiedliche Priorität von Prozessen, was besonders nachteilig für interaktive Systeme ist, in denen schnelle Antwortzeiten von höchster Relevanz sind. Diese Mängel machen \ac{FCFS} für viele moderne Anwendungen unpraktikabel. Daher wird im folgenden der OS Scheduling Algorithmus Round Robin näher betrachtet, welcher versucht eine schnellere Antwortzeit zu ermöglichen.

%\textit{Referenzen:}
%\begin{itemize}
%	\item Silberschatz, A., Galvin, P. B., \& Gagne, G. (2018). Operating System Concepts. Wiley.
%	\item Stallings, W. (2012). Operating Systems: Internals and Design Principles. Prentice Hall.
%	\item Tanenbaum, A. S., \& Bos, H. (2014). Modern Operating Systems. Pearson.
%\end{itemize}

\section{Round Robin}
Round Robin ist ein weit verbreiteter OS Scheduling-Algorithmus in Betriebssystemen, welcher für seine Fairness und Eignung für Zeitscheiben-basiertes Multitasking bekannt ist. Dieser Algorithmus weist jedem Prozess in der Warteschlange ein festes Zeitintervall, auch bezeichnet als Quantum, zu. Nach Ablauf des Quantums wird der aktuell laufende Prozess unterbrochen und an das Ende der Warteschlange gestellt, um dem nächsten Prozess in der Warteschlange \ac{CPU}-Zeit zuweisen zu können. Diese Methode gewährleistet, dass alle Prozesse regelmäßige \ac{CPU}-Zeit erhalten und kein Prozess andere blockiert, wie es bei \ac{FCFS} mit dem Convoy-Effekt der Fall ist. Durch diese Rotation wird eine gleichmäßigere Verteilung der \ac{CPU}-Zeit über alle Prozesse erreicht. % Tanenbaum und Bos (2014) 

\begin{algorithm}
	\caption{Round Robin Scheduling Algorithmus}
	\begin{algorithmic}[1]
		\Procedure{RoundRobin}{$processes$, $quantum$}
		\State $n \gets \text{length}(processes)$
		\State $time \gets 0$
		\State Initialize $remaining\_burst[n]$ with burst times of $processes$
		\While{any $remaining\_burst > 0$}
		\For{$i \gets 1$ to $n$}
		\If{$remaining\_burst[i] > 0$}
		\State $start\_time[i] \gets time$
		\State Execute process $i$ for $\min(remaining\_burst[i], quantum)$ time
		\State $time \gets time + \min(remaining\_burst[i], quantum)$
		\State $remaining\_burst[i] \gets remaining\_burst[i] - \min(remaining\_burst[i], quantum)$
		\If{$remaining\_burst[i] = 0$}
		\State $finish\_time[i] \gets time$
		\State $waiting\_time[i] \gets finish\_time[i] - processes[i].burst - processes[i].arrival$
		\State $turnaround\_time[i] \gets finish\_time[i] - processes[i].arrival$
		\EndIf
		\EndIf
		\EndFor
		\EndWhile
		\State \textbf{return} $start\_time$, $finish\_time$, $waiting\_time$, $turnaround\_time$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Abbildung \ref{alg:rr} zeigt Pseudocode für die Implementation des Round Robin Scheduling Algorithmus für einen Satz von Prozessen. Jeder Prozess wird für eine Zeitdauer bis zum definierten Quantum ausgeführt. Der Algorithmus berechnet Start- und Endzeiten, Wartezeiten und Umlaufzeiten für jeden Prozess. 

Ein wesentlicher Vorteil des Round Robin-Algorithmus ist dessen Fähigkeit, eine niedrige Antwortzeit für alle Prozesse zu gewährleisten, weshalb dieser besonders für interaktive Systeme von hoher Eignung ist. Da jeder Prozess innerhalb eines bestimmten Zeitrahmens bedient wird, kommt es nicht zu langen Wartezeiten bis die Prozesse \ac{CPU}-Zeit zugeteilt bekommen. Diese Eigenschaft wird von Silberschatz, Galvin und Gagne (2018) als entscheidend für Systeme mit hoher Prozessanzahl und Anforderungen an die Reaktionsfähigkeit angesehen, wie es bei modernen Betriebssystemen der Fall ist. 

Allerdings weist Round Robin auch Nachteile auf. Ein wesentlicher Punkt ist hierbei die Wahl der Länge des Zeitquantums. Bei einem zu kurzen Quantum, kommt es durch den Round Robin Algorithmus zu häufigen Prozesswechseln, wodurch ein Overhead entsteht und hierdurch die \ac{CPU}-Effizient verringert wird. % Stallings (2012)
Wenn allerdings ein zu langes Quantum gewählt wird, verlängern sich die Antwortzeiten für Prozesse und in extremen Fällen kann es zum gleichen Convoy-Effekt wie bei \ac{FCFS} kommen. Daher ist die Optimierung des Quantums abhängig von den spezifischen Anwendungsumgebungen und von hoher Relevanz. Ein weiterer Nachteil, ähnlich wie bei \ac{FCFS} ist die fehlende Betrachtung von unterschiedlichen Prioritäten der eingehenden Prozesse. Im folgenden wird ein weiterer OS Scheduling Algorithmus beschrieben, welcher versucht diese Herausforderung eines prioritäten-basierten Schedulings zu beheben. 

Insgesamt bietet der Round Robin-Algorithmus eine ausgewogene Lösung für das Scheduling-Problem, insbesondere in Umgebungen, bei welchen Fairness und schnelle Antwortzeiten gefordert sind. Seine Einfachheit und Effizienz machen ihn zu einer beliebten Wahl in vielen Betriebssystemen.

%\textit{Referenzen:}
%\begin{itemize}
%	\item Tanenbaum, A. S., \& Bos, H. (2014). Modern Operating Systems. Pearson.
%	\item Silberschatz, A., Galvin, P. B., \& Gagne, G. (2018). Operating System Concepts. Wiley.
%	\item Stallings, W. (2012). Operating Systems: Internals and Design Principles. Prentice Hall.
%\end{itemize}


\section{Multilevel Queue Scheduling}
Die Prozesse, welche ein modernes Betriebssystem verarbeitet kann in unterschiedliche Kategorien unterteilt werden. So gibt es beispielsweise interaktive Prozesse, bei welchen eine schnelle Antwortzeit essentiell ist, und Hintergrundprozesse, welche nicht direkt abgearbeitet werden müssen. Für gewöhnlich haben interaktive Prozesse daher eine höhere Priorität und müssen daher schneller \ac{CPU}-Zeit zugeteilt bekommen. \ac{MLQ} Scheduling ist ein fortgeschrittener Scheduling-Algorithmus, welcher versucht diese Prozesse mit unterschiedlichen Prozessen effizient zu verwalten. Bei \ac{MLQ} wird die Prozesswarteschlange in mehrere separate Warteschlangen aufgeteilt, wobei jede Warteschlange eine eigene Prioritätsebene besitzt. Eingehende Prozesse werden nun basierend auf ihrer Priorität in die jeweilig zuständige Warteschlange eingeteilt. Jede dieser Warteschlangen hat nun einen eigenen Scheduling-Algorithmus, um eine differenzierte Behandlung der Prozesse zu ermöglichen. % Silberschatz, Galvin und Gagne (2018)
Bei der Verarbeitung der Prozesse wird nun stets die Warteschlange mit der höheren Priorität zuerst abgearbeitet, bis diese vollständig entleert wurde. Anschließend fängt die Verarbeitung der nächst-geringeren Prioritätsstufe an. Sofern ein Prozess mit höherer Priorität nun eintreffen sollte, wird die Verarbeitung der Warteschlange mit geringerer Priorität pausiert. 

\begin{algorithm}
	\caption{Multilevel Queue Scheduling Algorithmus mit \ac{FCFS} and Round Robin}
	\label{alg:mlq}
	\begin{algorithmic}[1]
		\Procedure{MLQ}{$queues$, $processes$, $quantum$}
		\State Assign each process to a queue based on its priority or category
		\For{each $queue$ in $queues$}
		\If{queue is for interactive tasks}
		\State Apply Round Robin Scheduling (Refer to Round Robin Algorithm) with quantum $quantum$
		\State Execute interactive tasks in $queue$ using RR
		\ElsIf{queue is for background tasks}
		\State Apply First-Come, First-Served Scheduling (Refer to FCFS Algorithm)
		\State Execute background tasks in $queue$ using FCFS
		\EndIf
		\EndFor
		\State \textbf{return} scheduling results for each process
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Der Pseudocode aus Abbildung \ref{alg:mlq} beschreibt, wie bei \ac{MLQ} verschiedene Warteschlangen für interaktive und Hintergrundtasks verwendet werden, wobei für interaktive Tasks der Round Robin und für Hintergrundtasks der \ac{FCFS} angewendet wird.

Der zentrale Vorteil von \ac{MLQ} liegt in dessen Flexibilität und Effizienz bei der Behandlung verschiedener Prozesstypen. Beispielsweise können Systemprozesse, interaktive Prozesse und Batch-Prozesse in verschiedenen Warteschlangen mit entsprechenden Prioritäten und Scheduling-Strategien verwaltet werden. Hierdurch wird eine bessere Anpassung an die Anforderungen spezifischer Prozesstypen erreicht, was zu einer verbesserten Gesamtleistung des Systems führt. % Tanenbaum und Bos (2014) 

Ein Nachteil von \ac{MLQ} liegt allerdings in seiner Komplexität, sowohl in der Implementierung als auch im Management. Die korrekte Einordnung von Prozessen in Warteschlangen und die Auswahl geeigneter Scheduling-Algorithmen für jede Warteschlange erfordern sorgfältige Planung und ständige Anpassung. Eine nachteilige Auswahl und Konfiguration dieser Algorithmen kann zu einem erhöhten Overhead führen und die Systemeffizienz negativ beeinträchtigen. % Stallings (2012)

Trotz dieser Herausforderungen ist \ac{MLQ} ein beliebter Scheduling Algorithmus in Betriebssystemen, insbesondere dort, wo eine Vielzahl unterschiedlicher Prozesse und Anforderungen effizient verwaltet werden muss.

%\textit{Referenzen:}
%\begin{itemize}
%	\item Silberschatz, A., Galvin, P. B., \& Gagne, G. (2018). Operating System Concepts. Wiley.
%	\item Tanenbaum, A. S., \& Bos, H. (2014). Modern Operating Systems. Pearson.
%	\item Stallings, W. (2012). Operating Systems: Internals and Design Principles. Prentice Hall.
%\end{itemize}

% MLQ Text Benedikt eine erste Version (kann ggf. mit dem oberen zusammengeführt werden)
Aufbauen auf anderen Prozess-Schedulern, wie bspw. den zuvor beschriebenen First Come First Serve oder Round-Robin Prinzip gibt es weitere Verfahren, welche durch eine erweiterte Komplexität beabsichtigen zuvor entwickelte Prinzipien und Stärken zu vereinen und Schwächen zu umgehen. Eines dieser Verfahren ist das Multilevel Queue Scheduling. Es handelt sich hierbei um einen Algorithmus, bei welchem Prozess abhängig ihrer Eigenschaften in verschiedene Kategorien eingeteilt und anschließend entsprechend mit unterschiedlicher Priorität bearbeitet werden. Es soll somit, durch das Priorisieren von zeitkritischen Aufgaben und der dynamischen Ressourcenzuweisung, dem Ziel einer gerechten und effizienten Prozessverwaltung weiter nähergekommen werden.
Beim Multilevel Queue Scheduling Verfahren werden zunächst die aktuell offenen, zu bearbeitenden Prozesse unterschiedlichen Warteschlangen dauerhaft zugewiesen. Diese Einteilung kann auf Grundlage unterschiedlicher Kriterien geschehen und ausschlaggebend können Speichergröße, Prozesspriorität oder der Prozesstyp sein. Eine einfache Aufteilung ist beispielweise die Zuordnung in Vordergrundaktivitäten und Hintergrundaktivitäten sodass die erstere Gruppe interaktive Prozess umfasst welche zeitnah abgearbeitet werden müssen und die zweitere Gruppe eher statische Prozesse die ggf. auch länger für die Bearbeitung benötigen. Jede der so geformten Warteschlagen kann unabhängig, auf unterschiedliche Art und Weise bearbeitet werden und verfügt über einen eigenen Scheduling-Algorithmus. So ist es bspw. üblich die Warteschlange für Vordergrundaktivitäten nach dem Round Robin Prinzip abgearbeitet werden, währen bei der zweiten Warteschlange der Hintergrundaktivitäten das First Come First Serve Prinzip Anwendung findet. Dies hat den Hintergrund, dass ? %TODO: Eigenschaften RR, FCFS nochmal angucken und erlärung beenden 
Neben der unterschiedlichen Verfahren die innerhalb der Wartschlangen stattfinden gibt es ein einfaches Scheduling-Verfahren zur Verwaltung der Warteschlangen untereinander. Dieses ist für gewöhnlich mit einer festen Priorisierung und Präemptiv implementiert. Das bedeutet, dass Warteschlangen absolute Prioritäten über anderen haben und eine höher priorisierte Wartschlange zunächst vollständig abgearbeitet wird, gleichzeitig die Bearbeitung einer niedrig priorisieren Warteschlange aber zugunsten neuer Prozesse in einer anderen Schlange unterbrochen werden kann. 
In dem einfachen Beispiel mit zwei Warteschlangen würden daher zunächst die Vordergrundaktivitäten nach dem Round Robin Verfahren abgearbeitet und sobald diese Wartschlange leer ist die Hintergrundaktivitäten mittels First Come First Serve erledigt werden. Tritt während der Bearbeitung der Hintergrundaktivitäten ein Vordergrundprozess auf wird diese Bearbeitung solange unterbrochen, bis wieder alle Vordergrundaktivitäten abgearbeitet sind.
Das Verfahren ist hierbei nicht wie in diesem Beispiel auf zwei Warteschlangen beschränkt, sondern kann um eine Vielzahl an Schlangen für verschiedene Prozesseigenschaften erweitert werden, wie in Abbildung X dargestellt.
%TODO: ggf. Abbildung nachbauen.
Das Multilevel Queue Scheduling Verfahren bietet aufgrund seiner erweiterten Komplexität gegenüber herkömmlichen deutlich einfacheren Verfahren einige Vorteile aber auch Nachteile. So ist positiv zu bemerken, dass die Reaktionszeit des Systems durch die effizientere Ressourcenallokation reduziert werden kann und die Nutzererfahrung durch die schnellere Abarbeitung von interaktiven Prozessen verbessert wird. Desweiterem kann mit diesem Verfahren der Durchsatz gesteigert werden und das System ggf. auch Prozesse unterschiedlicher Schlangen gleichzeitig ausführen, welches zu der Effizienz des Systems beiträgt. Negativ zu betrachten ist hingegen die erhöhte Komplexität beim Design eines effizienten Systems, sowie der zusätzliche Arbeitsaufwand zur Verwaltung der mehreren Warteschlangen untereinander, welches die Performance des Systems wiederum lindern kann. Ein weiteres Problem ist das „Verhungern“ von Prozess in einer Warteschlange mit niedrigere Priorität, welches auftreten kann wenn zu viele, große Prozesse in anderen Schlangen zuerst abgearbeitet werden müssen.
Um diesem Nachteilen des „Verhungerns“ von Prozessen entgegenzuwirken gibt es Weiterentwicklungen der einfachen Multilevel Queue wie beispielsweise das heute verbreiterte Multilevel Feedback Queue Verfahren.
%TODO: ggf. MLFQ kurz erklären

% Hauptquelle: https://drive.uqu.edu.sa/_/mskhayat/files/MySubjects/2017SS%20Operating%20Systems/Abraham%20Silberschatz-Operating%20System%20Concepts%20(9th,2012_12).pdf S275


